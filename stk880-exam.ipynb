{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STK 880 Exam \n",
    "## Deidre Bredenkamp\n",
    "### 04639864"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "471ebed02f1d4600b638e033182978ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load your data into your Cluster.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0e9faf1f394d938cc85ec49534509f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = spark.read.option(\"delimiter\", \",\")\\\n",
    ".csv(\"s3://u04639864-stk-exam/e-64EYVOVT8HS1FUYLNDA2O6GDV/transactions_v2.csv\", header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Print out part of your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afbc96624f5d41659c9bfaa1e8454310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(msno='++6eU4LsQ3UQ20ILS7d99XK8WbiVgbyYL4FUgzZR134=', payment_method_id='32', payment_plan_days='90', plan_list_price='298', actual_amount_paid='298', is_auto_renew='0', transaction_date='20170131', membership_expire_date='20170504', is_cancel='0'), Row(msno='++lvGPJOinuin/8esghpnqdljm6NXS8m8Zwchc7gOeA=', payment_method_id='41', payment_plan_days='30', plan_list_price='149', actual_amount_paid='149', is_auto_renew='1', transaction_date='20150809', membership_expire_date='20190412', is_cancel='0'), Row(msno='+/GXNtXWQVfKrEDqYAzcSw2xSPYMKWNj22m+5XkVQZc=', payment_method_id='36', payment_plan_days='30', plan_list_price='180', actual_amount_paid='180', is_auto_renew='1', transaction_date='20170303', membership_expire_date='20170422', is_cancel='0'), Row(msno='+/w1UrZwyka4C9oNH3+Q8fUf3fD8R3EwWrx57ODIsqk=', payment_method_id='36', payment_plan_days='30', plan_list_price='180', actual_amount_paid='180', is_auto_renew='1', transaction_date='20170329', membership_expire_date='20170331', is_cancel='1'), Row(msno='+00PGzKTYqtnb65mPKPyeHXcZEwqiEzktpQksaaSC3c=', payment_method_id='41', payment_plan_days='30', plan_list_price='99', actual_amount_paid='99', is_auto_renew='1', transaction_date='20170323', membership_expire_date='20170423', is_cancel='0')]"
     ]
    }
   ],
   "source": [
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Print the data schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df60c5bef34646fc906ab3b29f3ecd76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- msno: string (nullable = true)\n",
      " |-- payment_method_id: string (nullable = true)\n",
      " |-- payment_plan_days: string (nullable = true)\n",
      " |-- plan_list_price: string (nullable = true)\n",
      " |-- actual_amount_paid: string (nullable = true)\n",
      " |-- is_auto_renew: string (nullable = true)\n",
      " |-- transaction_date: string (nullable = true)\n",
      " |-- membership_expire_date: string (nullable = true)\n",
      " |-- is_cancel: string (nullable = true)"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Convert all your fields to Integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b3b2c92a2e45eebfabb14d7c40602a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- msno: integer (nullable = true)\n",
      " |-- payment_method_id: integer (nullable = true)\n",
      " |-- payment_plan_days: integer (nullable = true)\n",
      " |-- plan_list_price: integer (nullable = true)\n",
      " |-- actual_amount_paid: integer (nullable = true)\n",
      " |-- is_auto_renew: integer (nullable = true)\n",
      " |-- transaction_date: integer (nullable = true)\n",
      " |-- membership_expire_date: integer (nullable = true)\n",
      " |-- is_cancel: integer (nullable = true)"
     ]
    }
   ],
   "source": [
    "cols=df.columns\n",
    "transactions=df\n",
    "for i in range(1,len(cols)+1):\n",
    "    l=i-1\n",
    "    var=cols[l]\n",
    "    df=df.withColumn(var, transactions[var].cast(IntegerType()))\n",
    "    \n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Write code to count how many distinct `payment_plan_days` are in this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef55150cb47149819d52c275afd66341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31"
     ]
    }
   ],
   "source": [
    "df.select(\"payment_plan_days\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eff39d039a5470389a5a1fa23dcf172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------+\n",
      "|features                                                  |\n",
      "+----------------------------------------------------------+\n",
      "|[32.0,90.0,298.0,298.0,0.0,2.0170131E7,2.0170504E7,0.0]   |\n",
      "|[41.0,30.0,149.0,149.0,1.0,2.0150809E7,2.0190412E7,0.0]   |\n",
      "|[36.0,30.0,180.0,180.0,1.0,2.0170303E7,2.0170422E7,0.0]   |\n",
      "|[36.0,30.0,180.0,180.0,1.0,2.0170329E7,2.0170331E7,1.0]   |\n",
      "|[41.0,30.0,99.0,99.0,1.0,2.0170323E7,2.0170423E7,0.0]     |\n",
      "|[41.0,30.0,149.0,149.0,1.0,2.0151112E7,2.0180613E7,0.0]   |\n",
      "|[41.0,30.0,99.0,99.0,1.0,2.0170313E7,2.0170413E7,0.0]     |\n",
      "|[41.0,30.0,99.0,99.0,1.0,2.0170318E7,2.0170418E7,0.0]     |\n",
      "|[41.0,30.0,99.0,99.0,1.0,2.0170316E7,2.0170416E7,0.0]     |\n",
      "|[41.0,30.0,149.0,149.0,1.0,2.0170307E7,2.0170407E7,0.0]   |\n",
      "|[41.0,30.0,99.0,99.0,1.0,2.0170316E7,2.0170416E7,0.0]     |\n",
      "|[40.0,30.0,149.0,149.0,1.0,2.0170311E7,2.017041E7,0.0]    |\n",
      "|[16.0,30.0,149.0,149.0,1.0,2.0170307E7,2.0170406E7,0.0]   |\n",
      "|[41.0,30.0,99.0,99.0,1.0,2.0170326E7,2.0170426E7,0.0]     |\n",
      "|[41.0,30.0,99.0,99.0,1.0,2.0170331E7,2.017043E7,0.0]      |\n",
      "|[41.0,30.0,99.0,99.0,1.0,2.0170308E7,2.0170408E7,0.0]     |\n",
      "|[41.0,30.0,149.0,149.0,1.0,2.0150731E7,2.0171202E7,0.0]   |\n",
      "|[32.0,410.0,1788.0,1788.0,0.0,2.0160805E7,2.0170919E7,0.0]|\n",
      "|[34.0,30.0,149.0,149.0,1.0,2.0170331E7,2.017043E7,0.0]    |\n",
      "|[41.0,30.0,99.0,99.0,1.0,2.0170304E7,2.0170404E7,0.0]     |\n",
      "+----------------------------------------------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "cols=transactions.columns\n",
    "cols.remove(\"msno\")\n",
    "# Use a Vector assembler to organise our features and labels\n",
    "assembler = VectorAssembler(inputCols=cols,outputCol=\"features\")\n",
    "# Now let us use the transform method to transform our dataset\n",
    "transactions=assembler.transform(transactions)\n",
    "transactions.select(\"features\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Why do we remove `msno` ?\n",
    "\n",
    "The `msno` variable, is a categorical variable, that seems to give the membership number. When looking at the data, this number looks like a mess, it contains numbers, letters and punctuation marks. But the main reason for us to remove this column, is that it does not provide us with any information, in other words it is not useful to retrieve any data from it. It will serve no purpose in statistical inference. Also it reduces the size of the data, making it easier and less computationally expensive to work with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into 70% train and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba847f1c35c45c3a20a829af3e0ed4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 734111\n",
      "Test Dataset Count: 314464"
     ]
    }
   ],
   "source": [
    "train, test = transactions.randomSplit([0.7, 0.3], seed=12345)\n",
    "print(\"Training Dataset Count: \" + str(train.count()))\n",
    "print(\"Test Dataset Count: \" + str(test.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Compute the proportion of the customers in this dataset who have churned\n",
    "\n",
    "Fit the Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca2d3b08dc2411187957f75a4bfc50c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = LogisticRegression(labelCol=\"is_cancel\", featuresCol=\"features\",maxIter=10)\n",
    "lrModel = lr.fit(train)\n",
    "\n",
    "predict_train=lrModel.transform(train)\n",
    "predict_test=lrModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dbd7288f739495eacca37875473024a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+----------+--------------------+\n",
      "|is_cancel|       rawPrediction|prediction|         probability|\n",
      "+---------+--------------------+----------+--------------------+\n",
      "|        0|[3.65307228070064...|       0.0|[0.97474304380262...|\n",
      "|        0|[3.65307227454412...|       0.0|[0.97474304365106...|\n",
      "|        0|[3.65307314777883...|       0.0|[0.97474306514925...|\n",
      "|        0|[3.65297228149979...|       0.0|[0.97474058180118...|\n",
      "|        0|[3.65303172452217...|       0.0|[0.97474204532912...|\n",
      "|        0|[3.65293094318831...|       0.0|[0.97473956397493...|\n",
      "|        0|[3.65374732750577...|       0.0|[0.97475965748363...|\n",
      "|        0|[3.65374933533812...|       0.0|[0.97475970688282...|\n",
      "|        0|[3.65374600922849...|       0.0|[0.97475962504969...|\n",
      "|        0|[3.65388265360103...|       0.0|[0.97476298673387...|\n",
      "|        0|[3.65396684843261...|       0.0|[0.97476505785290...|\n",
      "|        0|[3.65396676035784...|       0.0|[0.97476505568643...|\n",
      "|        0|[3.65300410522224...|       0.0|[0.97474136533331...|\n",
      "|        0|[3.65300331577216...|       0.0|[0.97474134589654...|\n",
      "|        0|[3.65300314751804...|       0.0|[0.97474134175401...|\n",
      "|        0|[3.65385523136493...|       0.0|[0.97476231213516...|\n",
      "|        0|[3.65385587816486...|       0.0|[0.97476232804692...|\n",
      "|        0|[3.65385492815631...|       0.0|[0.97476230467600...|\n",
      "|        0|[3.65385460186075...|       0.0|[0.97476229664889...|\n",
      "|        0|[3.65385515260109...|       0.0|[0.97476231019751...|\n",
      "+---------+--------------------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "The area under ROC for train set is 1.0\n",
      "The area under ROC for test set is 1.0"
     ]
    }
   ],
   "source": [
    "evaluator=BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\",\n",
    "labelCol=\"is_cancel\")\n",
    "\n",
    "predict_test.select(\"is_cancel\",\"rawPrediction\",\"prediction\",\"probability\").show(20)\n",
    "print(\"The area under ROC for train set\\\n",
    " is {}\".format(evaluator.evaluate(predict_train)))\n",
    "print(\"The area under ROC for test set\\\n",
    " is {}\".format(evaluator.evaluate(predict_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Comment on the results of your model based solely on your ROC and AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC curve (receiver operating characteristic curve), is a graph that visualises the performance of a classification model at all thresholds for classification.\n",
    "The ROC-AUC, is the area under the ROC curve, that gives a value to the performance of the model. In theory the higher the value for the AUC, the more accurate the model.\n",
    "The AUC value can range from 0 to 1. A model whose predictions are 100% wrong has an AUC of 0.0, but a model one whose predictions are 100% correct has an AUC of 1.0.\n",
    "In this case we have an AUC of 1 for both the test and train datasets, ie. the model predicts 100% accurately. \n",
    "\n",
    "In practice, this should be cause for concern, it could be an indication that the model is overfitting the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Write code to compute precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "619a4f5e10b243ba997d7aa0616337cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under PR-curve for train set is 1.0\n",
      "The area under PR-curve for test set is 1.0"
     ]
    }
   ],
   "source": [
    "evaluator_PR=BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\",\n",
    "labelCol=\"is_cancel\",metricName='areaUnderPR')\n",
    "\n",
    "print(\"The area under PR-curve for train set\\\n",
    " is {}\".format(evaluator_recall.evaluate(predict_train)))\n",
    "\n",
    "print(\"The area under PR-curve for test set\\\n",
    " is {}\".format(evaluator_recall.evaluate(predict_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Comment on your results solely based on precision and recall are you still happy with these\n",
    "findings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our results we see that the area under the Precision-Recall curve for both the testing and trainign set is equal to 1. \n",
    "In the previous question we discussed AUC-ROC, the ROC curve plots True Positive Rate Vs. False Positive Rate.\n",
    "Whereas, Precision-Recall curve plot Precision Vs. Recall. The Precision-Recall, displays more apparent differences in the misclassifications. \n",
    "\n",
    "Again the higher the value of the AUC the more accurate the model. So our AUC=1 for both the training and testing set, indicates that the model predicts with 100% accuracy. \n",
    "\n",
    "\n",
    "Since the values are the same as those for the ROC-AUC, it does provide some closure on the performance of the model, althought I am not 100% happy with the findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. If not, where do you think the issue is ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The issue could be that the model takes too many features into account leading to a model that overfits the data. This could be resolved by taking fewer features. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
